{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.cluster import KMeans \n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(augment=False, normalize=False):\n",
    "    digits = datasets.load_digits()\n",
    "    \n",
    "    if augment:\n",
    "        for image in digits.data:\n",
    "            for pixel in image:\n",
    "                if pixel<5:\n",
    "                    pixel = 0\n",
    "                elif pixel <10:\n",
    "                    pixel = 1\n",
    "                else:\n",
    "                    pixel = 2\n",
    "                    \n",
    "    data=digits.data\n",
    "    if normalize:\n",
    "        data = np.zeros(np.shape(digits.data))\n",
    "        for i,image in enumerate(digits.data):\n",
    "            data[i] = image/16\n",
    "    \n",
    "    temp = list(zip(data,digits.target))\n",
    "    random.shuffle(temp)\n",
    "\n",
    "    train = temp[0:int(len(temp)*0.7)]\n",
    "    test = temp[int(len(temp)*0.7):]\n",
    "\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    for x, y in train:\n",
    "        train_data.append(x)\n",
    "        train_target.append(y)\n",
    "    train_data = np.array(train_data)\n",
    "    train_target= np.array(train_target)\n",
    "\n",
    "    test_data = []\n",
    "    test_target = []\n",
    "    for x, y in test:\n",
    "        test_data.append(x)\n",
    "        test_target.append(y)\n",
    "    test_data = np.array(test_data)\n",
    "    test_target = np.array(test_target)\n",
    "    \n",
    "    return train_data,train_target,test_data,test_target, digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, stop):\n",
    "        self.stop_criteria = stop\n",
    "    \n",
    "    def fit(self,data,labels,n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_attributes = len(data[0])\n",
    "        self.n_pics = len(data)\n",
    "        pi = np.random.rand(self.n_classes)\n",
    "        means = np.random.rand(self.n_classes,self.n_attributes)\n",
    "        variances = np.random.rand(self.n_classes,self.n_attributes)\n",
    "        theta = [pi,means,variances]\n",
    "        \n",
    "        while True:\n",
    "            r = self.E_step(data,theta)\n",
    "            new_pi, new_mean, new_variances = self.M_step(r,data)\n",
    "            diff_mean = np.max(abs(theta[1] - new_mean))\n",
    "            diff_variances = np.max(abs(theta[2] - new_variances))\n",
    "            print(diff_mean,diff_variances)\n",
    "            if(diff_mean <self.stop_criteria and diff_variances <self.stop_criteria ):\n",
    "                self.means = new_mean\n",
    "                self.vars = new_variances\n",
    "                self.theta = [new_pi, new_mean, new_variances]\n",
    "                break\n",
    "            theta = [new_pi, new_mean, new_variances]\n",
    "        \n",
    "        self.cluster2label = {x:[] for x in range(10)}\n",
    "        for i ,pic in enumerate(data):\n",
    "            index = self.predict_cluster(pic)\n",
    "            self.cluster2label[index].append(labels[i])\n",
    "        for i in range(len(self.cluster2label)):\n",
    "            self.cluster2label[i] = self.most_frequent(self.cluster2label[i])\n",
    "    \n",
    "    def most_frequent(self,List): \n",
    "        occurence_count = Counter(List) \n",
    "        return occurence_count.most_common(1)[0][0]\n",
    "            \n",
    "    def predict_cluster(model,pic):\n",
    "        cluster_prob=np.zeros(10)\n",
    "        for number in range(model.n_classes):\n",
    "            cluster_prob[number] = model.P_X_theta(pic,model.theta,number)\n",
    "        return np.argmax(cluster_prob)\n",
    "    \n",
    "    def P_X_theta(self,x,theta,k):\n",
    "        val = 1\n",
    "        for j in range(self.n_attributes):\n",
    "            exp = math.exp( -( (x[j]-theta[1][k][j])**2 ) / (2*theta[2][k][j]) )\n",
    "            den = math.sqrt(2*math.pi*theta[2][k][j])\n",
    "            val*=(exp/den)\n",
    "        return val\n",
    "        \n",
    "    def E_step(self,X,theta):\n",
    "        r = np.zeros((self.n_pics,self.n_classes))\n",
    "        P_vec = np.zeros((self.n_pics,self.n_classes))\n",
    "        for i in range(self.n_pics):\n",
    "            for k in range(self.n_classes):\n",
    "                P_vec[i][k] = self.P_X_theta(X[i],theta,k)\n",
    "                \n",
    "        den = np.sum(P_vec,axis=1)\n",
    "        for i in range(self.n_pics):\n",
    "            if den[i] == 0:\n",
    "                r[i] == np.zeros(self.n_classes)\n",
    "                continue\n",
    "            for k in range(self.n_classes):\n",
    "                r[i][k] = theta[0][k] * self.P_X_theta(X[i],theta,k)/den[i]\n",
    "        return r\n",
    "                \n",
    "    def M_step(self,r,X):\n",
    "        new_r = np.zeros(self.n_classes)\n",
    "        for k in range(self.n_classes):\n",
    "            for i in range(self.n_pics):\n",
    "                new_r[k] += r[i][k]\n",
    "        new_pi = new_r / self.n_pics\n",
    "        \n",
    "        new_mean = np.zeros((self.n_classes,self.n_attributes))\n",
    "        new_variances = np.zeros((self.n_classes,self.n_attributes))\n",
    "        \n",
    "        for k in range(self.n_classes):\n",
    "            val = 0\n",
    "            val2 = 0\n",
    "            for i in range(self.n_pics):\n",
    "                val += r[i][k] * X[i]\n",
    "                val2 += r[i][k] * np.outer(X[i],X[i])\n",
    "            val /= new_r[k]\n",
    "            val2 /= new_r[k] \n",
    "            new_mean[k] = val\n",
    "            new_variances[k] = np.diag(val2 - np.outer(new_mean[k],new_mean[k]))\n",
    "        \n",
    "        new_variances += np.ones((10,64))*0.001\n",
    "        return new_pi, new_mean, new_variances\n",
    "\n",
    "train_data,train_target,test_data,test_target, labels = load_data(normalize=True)\n",
    "model_2 = Model(0.005)\n",
    "model_2.fit(train_data,train_target,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,pic):\n",
    "    cluster_prob=np.zeros(10)\n",
    "    for number in range(model.n_classes):\n",
    "        cluster_prob[number] = model.P_X_theta(pic,model.theta,number)\n",
    "    return model.cluster2label[np.argmax(cluster_prob)]\n",
    "\n",
    "def predict_cluster(model,pic):\n",
    "    cluster_prob=np.zeros(10)\n",
    "    for number in range(model.n_classes):\n",
    "        cluster_prob[number] = model.P_X_theta(pic,model.theta,number)\n",
    "    return np.argmax(cluster_prob)\n",
    "\n",
    "def evaluate_model(model):\n",
    "    y_pred = []\n",
    "    for i, val in enumerate(test_target):\n",
    "        y_pred.append(predict_cluster(model,test_data[i]))\n",
    "    conf_mat = metrics.confusion_matrix(test_target, y_pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(test_target, y_pred))\n",
    "    model.cluster2label = {x:[] for x in range(10)}\n",
    "    for i in range(10):\n",
    "        max_index = 0\n",
    "        max_value = 0\n",
    "        for j in range(10):\n",
    "            if conf_mat[j][i] > max_value:\n",
    "                max_value = conf_mat[j][i] \n",
    "                max_index = j\n",
    "        max_in_row = np.max(conf_mat[max_index])\n",
    "        print(max_value,max_in_row)\n",
    "        if max_value == max_in_row:\n",
    "            print(\"Assigned \" + str(i) + \" to \" + str(max_index))\n",
    "            model.cluster2label[i] = max_index\n",
    "        else:\n",
    "            min_val = 0\n",
    "            min_index = 0\n",
    "            for k in range(10):\n",
    "                if min_val < np.argmax(conf_mat[k]):\n",
    "                    min_val = np.argmax(conf_mat[k])\n",
    "                    min_index = k\n",
    "            model.cluster2label[i] = min_index\n",
    "    y_pred = []\n",
    "    for i, val in enumerate(test_target):\n",
    "        y_pred.append(predict(model,test_data[i]))  \n",
    "\n",
    "    print(\"Classification report:\\n%s\\n\"\n",
    "      % (metrics.classification_report(test_target, y_pred)))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(test_target, y_pred))\n",
    "\n",
    "print(model_2.cluster2label)\n",
    "evaluate_model(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_2.cluster2label)\n",
    "evaluate_model(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List): \n",
    "    occurence_count = Counter(List) \n",
    "    return occurence_count.most_common(1)[0][0]\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(train_data)\n",
    "class2label = {x:[] for x in range(10)}\n",
    "for i ,pic in enumerate(train_data):\n",
    "    class2label[kmeans.labels_[i]].append(train_target[i])\n",
    "for i in range(len(class2label)):\n",
    "    class2label[i] = most_frequent(class2label[i])\n",
    "    \n",
    "y_pred = []\n",
    "for i, val in enumerate(test_target):\n",
    "    y_pred.append(class2label[kmeans.predict([test_data[i]])[0]])\n",
    "\n",
    "print(\"Classification report:\\n%s\\n\"\n",
    "  % (metrics.classification_report(test_target, y_pred)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(test_target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
